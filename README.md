# AI Contract Drift Monitor

> Professional boilerplate for monitoring external APIs with contract testing, proactive change detection (drift), and intelligent AI-powered alerts.

---

## ğŸ¯ What This Project Does

**Problem:** External APIs change without warning, breaking your production systems. You discover issues only when users complain.

**Solution:** This project provides:

1. **ğŸ“¸ Automatic Snapshots** - Captures API schemas automatically on first run
2. **ğŸ” Drift Detection** - Monitors APIs continuously for changes
3. **ğŸ¤– AI-Powered Analysis** - Explains what changed and the impact
4. **ğŸ“¢ Smart Alerts** - Notifies you via Teams, Email, or Console
5. **ğŸ“Š Visual Monitoring** - Ensures the monitoring system itself is healthy (meta-monitoring)

**Key Differentiator:** Not just testing - it's a complete monitoring system that learns your API structure and alerts you proactively when things change.

---

## ğŸ—ï¸ Architecture

This project follows **Clean Architecture** principles with clear separation of concerns:

```
src/
â”œâ”€â”€ domain/                 # Business logic & entities
â”‚   â”œâ”€â”€ entities/          # Core business entities
â”‚   â””â”€â”€ repositories/      # Repository interfaces
â”œâ”€â”€ application/           # Use cases & orchestration
â”‚   â””â”€â”€ use-cases/        # Business use cases
â””â”€â”€ infrastructure/        # External concerns
    â”œâ”€â”€ api/
    â”‚   â””â”€â”€ tests/        # Contract tests
    â”œâ”€â”€ llm/              # AI integration
    â”œâ”€â”€ monitoring/       # Metrics & monitoring
    â””â”€â”€ notifications/    # Alert channels
```

## ğŸš€ Quick Start

### 1. Start the monitoring stack:
```bash
npm run start
```

### 2. Access Grafana:
- **URL:** http://localhost:3001
- **Login:** admin / admin
- **Dashboard:** Will load automatically!

### 3. Run drift check:
```bash
npm run drift
```

## ğŸ“Š What You Get

- âœ… **Contract Testing** - API schema validation with Playwright
- âœ… **Drift Detection** - Proactive change monitoring of external APIs
- âœ… **AI Summaries** - Intelligent impact analysis of changes
- âœ… **Multi-channel Alerts** - Teams, Email, Console
- âœ… **Automatic Dashboard** - Loads on first access
- âœ… **System Health Metrics** - Monitor the monitoring system (CPU, Memory, Disk, Network)
- âœ… **Meta-Monitoring** - Redundancy layer ensuring the monitor itself is healthy

## ğŸ¯ Commands

| Command | Description |
|---------|-------------|
| `npm run start` | Start Docker services (Prometheus, Grafana, Node Exporter) |
| `npm run drift` | Run drift check and detect API changes |
| `npm run metrics` | Start application metrics server (port 9091) |
| `npm run test:contracts` | Run contract tests with Playwright |

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file:

```bash
# AI Configuration (optional)
AI_GATEWAY_URL=https://your-ai-gateway.com
AI_API_KEY=your-ai-key

# Teams Notifications (optional)
TEAMS_WEBHOOK_URL=https://teams.webhook.url

# Email Notifications (optional)
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASS=your-app-password
SMTP_FROM=your-email@gmail.com
EMAIL_TO=recipient@example.com
```

## ğŸ†• Adding New APIs to Monitor

### Step 1: Define the API Target

Add to `src/infrastructure/api/tests/targets.json`:

```json
{
  "id": "my_api",
  "method": "GET",
  "url": "https://api.example.com/data",
  "headers": {
    "Authorization": "Bearer YOUR_TOKEN"  // Optional
  }
}
```

### Step 2: Create Contract Test

Create `src/infrastructure/api/tests/my-api-contract.spec.ts`:

```typescript
import { test, expect, request as pwRequest } from '@playwright/test';
import { z } from 'zod';

const MySchema = z.object({
  field: z.string()
});

test('My API contract', async () => {
  const req = await pwRequest.newContext();
  const res = await req.get('https://api.example.com/data');
  expect(res.status()).toBe(200);
  const json = await res.json();
  expect(MySchema.safeParse(json).success).toBe(true);
});
```

### Step 3: Run Drift Check (The Magic! âœ¨)

```bash
npm run drift
```

**What happens:**

1. **ğŸ“¸ First Run - Snapshot Creation:**
   - Fetches the API response
   - Extracts the schema structure (keys and types)
   - **Automatically creates** `snapshots/latest.json`
   - Saves the baseline for future comparisons

2. **ğŸ” Subsequent Runs - Drift Detection:**
   - Fetches current API response
   - Compares with saved snapshot
   - Detects any schema changes (new fields, removed fields, type changes)
   - If changes detected:
     - ğŸ¤– AI generates impact summary
     - ğŸ“¢ Sends alerts (Teams/Email/Console)
     - ğŸ’¾ Updates snapshot with new structure
     - ğŸ”„ **Auto-commits** updated snapshot to repository (in CI/CD)

**Example Snapshot:**
```json
{
  "my_api": {
    "field": "string",
    "count": "number",
    "active": "boolean"
  }
}
```

**This is the core value:** You don't need to manually define schemas. The system learns your API structure automatically and monitors it forever! ğŸ¯

---

## ğŸ”„ Automatic Snapshot Commits (CI/CD Only)

**When running in GitHub Actions**, detected changes trigger an automatic workflow:

### What Happens:
1. **Drift detected** â†’ API schema changed
2. **Snapshot updated** â†’ New structure saved to `snapshots/latest.json`
3. **Auto-commit** â†’ GitHub Actions commits the change:
   ```
   chore: update API snapshots [skip ci]
   ```
4. **Push to main** â†’ Changes pushed automatically
5. **No PR needed** â†’ Direct commit to main branch

### Why Direct Commit?
- âœ… Snapshots are **non-breaking changes** (just documentation)
- âœ… You already received **alerts** (Teams/Email) about the change
- âœ… You can **review the commit** in GitHub history
- âœ… If needed, you can **revert** the commit

### Review Process:
1. **Alert received** â†’ Check Teams/Email notification
2. **AI Summary** â†’ Understand the impact
3. **GitHub commit** â†’ Review snapshot diff in repository
4. **Action** â†’ If problematic, revert or contact API owner

**Note:** The `[skip ci]` flag prevents infinite loops by not triggering another pipeline run.

---

## ğŸ“ˆ Monitoring Stack (Meta-Monitoring)

**Purpose:** Monitor the monitoring system itself - ensure your drift detection is always running.

### Local Monitoring (Visual Dashboard)

- **Prometheus** (http://localhost:9090) - Collects metrics from the monitoring infrastructure
- **Grafana** (http://localhost:3001) - Visual dashboard showing system health
- **Node Exporter** (http://localhost:9100) - System metrics (CPU, Memory, Disk, Network)

**What it monitors:**
- âœ… Is the drift check service running?
- âœ… Is the system healthy? (CPU, RAM, Disk)
- âœ… Are there any performance issues?

**To use:** Run `npm run start` locally and access http://localhost:3001

### CI/CD Monitoring (Metrics Snapshots)

**In GitHub Actions**, metrics are saved as downloadable artifacts:

- **metrics_TIMESTAMP.txt** - Complete Prometheus metrics
- **health_TIMESTAMP.json** - Health check status
- **metrics_summary.md** - Summary report

**To access:**
1. Go to Actions tab
2. Select a workflow run
3. Download **metrics-snapshot-{run_id}** artifact

**Retention:** 30 days

**Think of it as:** A redundancy layer - if your monitoring system goes down, you'll know immediately from the dashboard. It's "monitoring the monitor" to ensure reliability.

## ğŸ’¡ AI-Powered Summaries

Configure `AI_GATEWAY_URL` and `AI_API_KEY` in `.env` to enable intelligent impact analysis:

**Without AI:**
```
Field 'deprecated' was added to schema
```

**With AI:**
```
âš ï¸ Field 'deprecated' added - indicates API may be discontinued soon, consumers should migrate
```

The AI analyzes schema changes and explains business impact, not just technical diff.

## ğŸ› ï¸ Technologies

- **TypeScript** - Type-safe development
- **Playwright** - HTTP contract testing
- **Zod** - Schema validation
- **Prometheus** - Metrics & observability
- **Grafana** - Dashboards & visualization
- **Docker** - Containerized infrastructure

## ğŸ“„ License

MIT